\documentclass[a4paper,UKenglish,cleveref]{lipics-v2019}

\overfullrule=1mm

\usepackage{bussproofs}
\EnableBpAbbreviations

\newcommand{\agdaSymb}[1]{\mathsf{#1}}
\newcommand{\agdaKW}[1]{\mathbf{#1}}

\newcommand{\ind}{\hspace{1em}}

\newcommand{\data}{\agdaKW{data}}
\newcommand{\where}{\agdaKW{where}}
\newcommand{\Alet}{\agdaKW{let}}
\newcommand{\Ain}{\agdaKW{in}}

\newcommand{\Set}{\agdaSymb{Set}}
\newcommand{\Prop}{\agdaSymb{Prop}}
\newcommand{\Ty}{\agdaSymb{Ty}}
\newcommand{\Con}{\agdaSymb{Con}}
\newcommand{\Tms}{\agdaSymb{Sub}}
\newcommand{\Tm}{\agdaSymb{Tm}}
\newcommand{\id}{\agdaSymb{id}}
\newcommand{\app}{\agdaSymb{app}}
\newcommand{\lam}{\lambda}
\newcommand{\vz}{\agdaSymb{vz}}
\newcommand{\vs}{\agdaSymb{vs}}
\newcommand{\Var}{\agdaSymb{Var}}
\newcommand{\Vars}{\agdaSymb{Wk}}
\newcommand{\wk}{\agdaSymb{wk}}
%\newcommand{\Ne}{\agdaSymb{Ne}}
\newcommand{\Val}{\agdaSymb{Val}}
\newcommand{\Env}{\agdaSymb{Env}}
\newcommand{\NV}{\agdaSymb{NV}}
\newcommand{\var}{\agdaSymb{var}}
\newcommand{\neu}{\agdaSymb{neu}}
\newcommand{\clos}{\agdaSymb{clos}}
\newcommand{\qVal}{\agdaSymb{qVal}}
\newcommand{\qEnv}{\agdaSymb{qEnv}}
\newcommand{\idenv}{\agdaSymb{idenv}}
\newcommand{\Nf}{\agdaSymb{Nf}}
\newcommand{\NN}{\agdaSymb{NN}}
\newcommand{\eval}{\agdaSymb{eval}}
\newcommand{\evals}{\agdaSymb{evals}}
\newcommand{\q}{\agdaSymb{quote}}
\newcommand{\qn}{\agdaSymb{quoten}}
\newcommand{\norm}{\agdaSymb{norm}}
\newcommand{\scv}{\agdaSymb{scv}}
\newcommand{\sce}{\agdaSymb{sce}}
\newcommand{\U}{\agdaSymb{U}}
\newcommand{\El}{\agdaSymb{El}}
\newcommand{\TV}{\agdaSymb{Ty^{sf}}}
\newcommand{\Sk}{\agdaSymb{Sk}}
\newcommand{\base}{\agdaSymb{base}}
\newcommand{\skel}{\agdaSymb{skeleton}}
\newcommand{\isSet}{\agdaSymb{set}}

\newcommand{\cul}{\ulcorner}
\newcommand{\cur}{\urcorner}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\Da}{\Downarrow}
\newcommand{\Beq}{\simeq_{\beta\eta}}
\newcommand{\lift}{\!\uparrow\!}


\nolinenumbers

\bibliographystyle{plainurl} % Mandatory style

\title{Big Step Normalisation for Type Theory}

\author{Thorsten Altenkirch}
{School for Computer Science, University of Nottingham, United Kingdom}
{txa@cs.nott.ac.uk}{}
{supported by COST Action EUTypes CA15123 and USAF, Airforce office for
  scientific research, award FA9550-16-1-0029}

\author{Colin Geniet}
{Computer Science Department, ENS Paris-Saclay, France}
{colin.geniet@ens-paris-saclay.fr}{}{}

\authorrunning{T. Altenkirch and C. Geniet}

\Copyright{Thorsten Altenkirch and Colin Geniet}

% mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm 
\ccsdesc[500]{Theory of computation~Type theory}

\keywords{Normalisation, big step normalisation, type theory, dependent types, Agda}

\supplement{\url{https://github.com/colingeniet/big-step-normalisation}}

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{}
\EventNoEds{0}
\EventLongTitle{}
\EventShortTitle{}
\EventAcronym{}
\EventYear{}
\EventDate{}
\EventLocation{}
\EventLogo{}
\SeriesVolume{}
\ArticleNo{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

\begin{abstract}
  Big step normalisation is a normalisation method for typed lambda-calculi
  which relies on a purely syntactic recursive evaluator. Termination of that
  evaluator is proven using a predicate called strong computability, similar to
  the techniques used to prove strong normalisation of $\beta$-reduction for
  typed lambda-calculi. We generalise big step normalisation to a minimalist
  dependent type theory. Compared to previous presentations of big step
  normalisation for e.g.\ the simply-typed lambda-calculus, we use a quotiented
  syntax of type theory, which crucially reduces the syntactic complexity
  introduced by dependent types. Most of the proof has been formalised using
  Agda.
\end{abstract}

\section{Introduction}
\subsection{Normalisation}
In the context of typed lambda-calculi, normalisation refers to the process of
computing a canonical representative, called normal form, in each
$\beta\eta$-equivalence class of terms.
A very general definition of normalisation, previously used in
e.g.~\cite{altenkirch1995categorical,chapman2009bsn,kaposi2016normalisation},
is the following.
Normalisation is given by a set of normal forms and two (computable) maps:
$\norm$ from terms to normal forms,
and an embedding $\cul\_\cur$ of normal forms into terms, satisfying

\begin{description}
\item[soundness] If $u \Beq v$, then $\norm\ u = \norm\ v$
\item[completeness\footnotemark] For every term $u$, $\cul \norm\ u \cur \Beq u$
\item[stability] For every normal form $n$, $\norm\ \cul n \cur = n$
\end{description}%
\footnotetext{The choice of the words \emph{soundness} and
  \emph{completeness} comes from viewing normal forms as a model.}

The traditional way to define a normalisation function is through rewriting
theory. One proves that $\beta\eta$-reduction is confluent, and terminates%
\footnote{%
  We do not use the words strong or weak normalisation to refer to termination
  of the rewriting process, so as to avoid ambiguity with the generalised notion
  of normalisation introduced.
}
on typed terms. Normal forms are defined as terms which can not be
$\beta\eta$-reduced, and normalisation is done by reducing a term until reaching
a normal form. Termination and confluence ensure the correctness
of the definition. Soundness also follows from confluence, while completeness
and stability are immediate. See for instance~\cite{girard1989proofs} for a
detailed proof of this result for the simply-typed lambda-calculus and some
variants (System F, System T). Unfortunately, problems arise for some other
variants of the lambda-calculus. For instance, the lambda-calculus with explicit
substitutions does not terminate in the strong sense~\cite{mellies1995explicit},
and the lambda-calculus with coproduct types (i.e.\ disjoint union) is not
confluent~\cite{dougherty1995coproducts}. While some of these issues can be worked
around, for instance by using weak termination and more restrictive reductions,
these problems have lead to the development of other methods.

One of them is \emph{normalisation by evaluation}~(NBE), introduced
by Berger and Schwichtenberg~\cite{berger1991inverse} for the simply-typed
lambda-calculus. The idea is to evaluate terms into a semantic model,
meaning for instance that $\lambda$-abstractions (syntactic functions) are interpreted
by actual (semantic) functions. A map from the model into normal forms is then
defined, giving rise to the normalisation function by composition with evaluation.
This method was for instance used to prove decidability of equivalence for the
lambda-calculus with coproducts~\cite{altenkirch2001normalization}.

\subsection{Big Step Normalisation}
\emph{Big step normalisation}~(BSN) is a purely syntactic normalisation
method, proposed in~\cite{chapman2009bsn} by Chapman and the first author for
the simply-typed lambda-calculus.  The normalisation algorithm is in two
parts. First, terms are evaluated by an environment machine, yielding
syntactic values. Then, values are mapped to normal forms by a function named
$\q$. Normalisation $\norm$ is done by evaluating in the identity environment,
then applying $\q$ on the resulting value.  The embedding $\cul\_\cur$ is the
inclusion of normal forms into terms.

Evaluation and $\q$ both have fairly simple definitions, but are
not structurally recursive, hence their termination is not obvious.
To prove termination, a Tait-style predicate~\cite{tait1967} called
\emph{strong computability} (SC) is defined on values:
\begin{itemize}
\item A value $v$ of the base type is strongly computable if normalisation
  terminates on $v$.
\item A value $f$ of a function type is SC if it preserves SC when applied to
  an argument.
\end{itemize}
The following results can then be proved.
\begin{itemize}
\item $\q$ terminates on any SC value, and conversely any neutral value (i.e.\
  a value which is not a $\lambda$-abstraction) on which
  $\q$ terminates is SC.
\item In a SC environment, evaluation terminates and yields SC results.
\end{itemize}
Termination of $\norm$ follows from these results. Completeness and
stability are straightforward. The proof of soundness is more involved, and
shares some similarities with the proof of termination, but replaces strong
computability with a binary relation on values.

\subsection{BSN for Type Theory and Quotiented Syntax}
Chapman also considered BSN for dependent type theory in~\cite{chapman2009type},
but did not provide a full proof of correctness, due to the syntactic
complexity added by dependent types.

In this work, we propose some methods to simplify the proof of BSN in the case
of dependent types, allowing us to complete it.
Notably, we use the quotiented syntax of type theory proposed
in~\cite{kaposi2016type}. By only considering terms quotiented by
$\beta\eta$-equivalence, the syntax becomes significantly lighter. For
instance, the coercion constructors which form a large part of the syntactic
boilerplate encountered in~\cite{chapman2009type} become unnecessary.

With a quotiented syntax, the notion of normalisation changes slightly. If
$\Beq$ is replaced with equality of quotiented terms in the first definition
of a normalisation function, then soundness simply states that $\norm$ is
correctly defined on the quotiented syntax, while completeness and stability
state that $\norm$ and $\cul\_\cur$ are inverse of each other.  This leads to
the following definition proposed in~\cite{kaposi2016normalisation}: a
normalisation function is simply an isomorphism between quotiented terms and
normal forms. Obviously, this definition requires a sensible notion of normal
forms---one can not consider quotiented terms to be normal forms, and identity
to be normalisation. Thus, we require normal forms to have a simple inductive
definition, which ensures decidability of equality.%
\footnote{%
  In the unquotiented case, the embedding of normal forms into terms (which can
  be proved to be injective) ensures that equality of normal forms is decidable,
  hence why no such restriction was required.
}

\subsection{Structure of the Paper}
\Cref{sec:theory} presents the metatheory, notation, and conventions used in this paper.

\Cref{sec:syntax} presents the quotiented syntax of type theory.

\Cref{sec:weakening} introduces a notion of weakening of contexts.

\Cref{sec:normalisation} defines big step normalisation itself. Because
it is not a priori clear that BSN defines a correct function (termination for
instance is problematic) we formally define normalisation by its big step
semantics, i.e.\ as a relation between inputs and output.

\Cref{sec:correctness} focuses on the two major correctness proofs:
termination and soundness. The proof of termination remains similar to the case
of simple types. The main difference is that we develop a simplified and
generalised induction principle for types, which allows us to manipulate
dependent types in almost the same way as simple types during the proof.
The proof of soundness for an unquotiented syntax seems much harder to
adapt, we instead provide a simple proof using soundness of NBE.

Finally, \cref{sec:cubical} explains how the proof of BSN can be
adapted to a cubical metatheory, using higher inductive types to encode
quotient inductive types.

\subsection{Related Work}
Big step semantics have previously been used for the purpose of normalisation.
For instance T.~Coquand uses a big step relation to decide conversion in type
theory~\cite{coquand1991conversion}, but relies on considerations on untyped
terms, and focuses on deciding conversion, rather than fully normalising terms.
P.B.~Levy uses Tait's method to prove termination of a big step semantics in
the case of a simple programming language~\cite{levy2001call}. Big step
normalisation was developed by Chapman and the first author for a combinatory
calculus~\cite{chapman2006tait}, and for the simply-typed
lambda-calculus~\cite{chapman2009bsn}. A generalisation to type theory was
proposed~\cite{chapman2009type}, but without a full proof of correctness.
The present paper can be seen as a continuation of these works.

An important difference compared to previous works on big step normalisation
is that we use a quotiented syntax of type theory. This builds upon the work by
Kaposi and the first author which provides a concise, quotiented syntax of type
theory within (a larger) type theory~\cite{kaposi2016type}, and formalises
normalisation by evaluation in this syntax~\cite{kaposi2016normalisation}.
This quotiented syntax is closely related to categories with
families~\cite{dybjer1995cwf,hofmann1997syntax}, in that the syntax is
essentially an initial category with families. The syntax is formalised using
quotient inductive-inductive types (QIIT), which were previously used
in~\cite{hott}---although not under that name---to e.g.\ define Cauchy reals
in type theory. More recently, the precise notion and semantics of QIIT has
been the subject of work such
as~\cite{altenkirch2018quotient,dijkstra2017quotient,kaposi2019quotient}.


\section{Metatheory and Notations}
\label{sec:theory}
The present work has been formalised using a cubical metatheory~\cite{cchm}
implemented by Agda~\cite{norell2007agda}. This cubical theory provides a simple
way to define quotient inductive inductive types (QIIT, cf.~\cite{kaposi2016type})
as a special case of higher inductive types. However, for simplicy, we prefer
to present this paper in a strict, intentional Martin-Löf Type Theory,
extended with QIIT. Functional extensionality is assumed, and can in fact be
proved using the interval quotient type. See \cref{sec:cubical} for a
discussion of the implementation in a cubical metatheory.

Our metatheoretic notations are loosely based on the syntax of Agda. Function
types are written as $(x : A) \to B$, or simply $A \to B$ for non-dependent
functions. For ease of notations, we sometimes use infix arguments, denoted by
underscores, e.g.\ $\_,\_$ applied to $x$ and $y$ is written as $x,y$.
Functions with implicit arguments are defined as $f : \{x : A\} \to B$, and the
argument can be either omitted, or given in subscript as $f_x$. Sum types
(dependent pairs) are denoted by $\Sigma(x : A),\ B$.
We denote by $\Set$ the universe of types, and by $\Prop$ the universe of mere
propositions, i.e.\ the types in which all elements are equal.
The equality type is denoted by $x \equiv y$, while $=$ is only used in
definitions. The transport of $x : P\ a$ along an equality $p : a \equiv b$ is
denoted by $_{p*}x : P\ b$. If $p : a \equiv b$, the type of dependent
equalities between $x : P\ a$ and $y : P\ b$ lying over $p$ is denoted by
$x \equiv^p y$. For simplicity and readability, transports and dependent
equality types will be omitted starting from \cref{sec:weakening}.

Inductive types are introduced by $\data$, the sort of the defined type, and
the signatures of the constructors. Inductive functions are defined by
pattern-matching. For instance:
\begin{flalign*}
  & \data\ \mathbb{N} : \Set\ \where
  && \_+\_ : \mathbb{N} \to \mathbb{N} \to \mathbb{N} && \\ & \ind
  \begin{alignedat}{2}
    & 0 && : \mathbb{N} \\
    & S && : \mathbb{N} \to \mathbb{N}
  \end{alignedat} &&
  \begin{alignedat}{2}
    & n + 0 && = n \\
    & n + (S\ m) && = S\ (n + m)
  \end{alignedat}
\end{flalign*}
Definitions of QIIT are similar, but allow \emph{equality} or \emph{quotient}
constructors, which build elements of equality types. A very simple example is the interval
type, defined by two endpoints and an equality between them.
\begin{flalign*}
  & \data\ \mathbb{I} : \Set\ \where \\ & \ind
  \begin{alignedat}{2}
    & a && : \mathbb{I} \\
    & b && : \mathbb{I} \\
    & p && : a \equiv b
  \end{alignedat}
\end{flalign*}
A function defined by induction on a QIIT must be defined inductively on
regular constructors, and must respect all quotient constructors, meaning that
it must map the elements equated by a quotient constructors to images which are
provably equal. For instance, to define a function on $\mathbb{I}$ by induction,
one must specify the images $f(a)$ and $f(b)$, then prove that $f(a) \equiv f(b)$.
The reader may refer to~\cite{kaposi2016type} for more details on QIIT.

Finally, all free variables in definitions and lemmas are implicitly
universally quantified. Omitted types can be inferred from the context and the
naming conventions.

\section{Quotiented Syntax of Type Theory}
\label{sec:syntax}
This section introduces the syntax of type theory based on QIIT proposed by
Kaposi and the first author in~\cite{kaposi2016type,kaposi2016normalisation}.
The reader should refer to the former for further details.

This syntax is intrinsically typed, with De Bruijn indices, and explicit
substitutions. Contexts, types, substitutions and terms are mutually defined.
We denote contexts by $\Gamma,\Delta,\Theta,\Phi$, types by $A,B,C$,
substitutions by $\sigma,\nu,\delta$, and terms by $s,t,u$.
\begin{align*}
  & \data\ \Con : \Set
  && \text{$\Con$ is the set of contexts} \\
  & \data\ \Ty : \Con \to \Set
  && \text{$\Ty\ \Gamma$ are the types in context $\Gamma$} \\
  & \data\ \Tms : \Con \to \Con \to \Set
  && \text{$\Tms\ \Gamma\ \Delta$ are the substitutions from $\Delta$ to $\Gamma$}\\
  & \data\ \Tm : (\Gamma : \Con) \to \Ty\ \Gamma \to \Set
  && \text{$\Tm\ \Gamma\ A$ are the terms of type $A$ in $\Gamma$}
\end{align*}

Syntax constructors follow closely the definition of a category with
families~\cite{dybjer1995cwf,hofmann1997syntax} with product types. Contexts
and substitutions form a category, types are a presheaf, and terms are a family
of presheaves over types. The constructor for dependent function types is
denoted by $\Pi$. There is a base type $\U$, and a base dependent family $\El$
indexed by $\U$. One may see $\U$ as a universe, i.e.\ a type whose elements
are types, when interpreted through $\El$---this is reflected by the names of
the constructors. Because we consider a minimalist type theory, it is only an
abstract universe, meaning that no element of $\U$ can be built in a
closed context. However, one may use contexts to postulate the existence of
types in $\U$.

The syntax constructors are listed below, with regular constructors on the
left, and equality constructors on the right.
\begin{flalign*}
  % Contexts
  & \data\ \Con\ \where \\ & \ind
  \begin{alignedat}{2}
    & \bullet && : \Con \\
    & \_,\_ && : (\Gamma : \Con) \to \Ty\ \Gamma \to \Con
  \end{alignedat} \\
  % Types
  & \data\ \Ty\ \where && \data\ \Ty\ \where \\ & \ind
  \begin{alignedat}{2}
    & \_[\_] && : \Ty\ \Delta \to \Tms\ \Gamma\ \Delta \to \Ty\ \Gamma \\
    & \U && : \Ty\ \Gamma \\
    & \El && : \Tm\ \Gamma\ \U \to \Ty\ \Gamma \\
    & \Pi && : (A : \Ty\ \Gamma) \to \Ty\ (\Gamma,A) \to \Ty\ \Gamma \\ &
  \end{alignedat} && \ind
  \begin{alignedat}{2}
    & [\id] && : A [ \id ] \equiv A \\
    & [\circ] && : A [ \sigma \circ \nu ] \equiv A [ \sigma ] [ \nu ] \\
    & \U[] && : \U [ \sigma ] \equiv \U \\
    & \El[] && : (\El\ u) [ \sigma ] \equiv \El(_{\U[] *} u [ \sigma ]) \\
    & \Pi[] && : (\Pi\ A\ B) [ \sigma ] \equiv \Pi (A[\sigma]) (B[\sigma \lift A])
  \end{alignedat}
  \displaybreak[0] \\
  % Substitutions
  & \data\ \Tms\ \where && \data\ \Tms\ \where \\ & \ind
  \begin{alignedat}{3}
    & \id       && :\ && \Tms\ \Gamma\ \Gamma \\
    & \_\circ\_ && : && \Tms\ \Delta\ \Theta \to \Tms\ \Gamma\ \Delta\ \to \Tms\ \Gamma\ \Theta \\
    & \epsilon  && : && \Tms\ \Gamma\ \bullet \\
    & \_,\_     && : && (\sigma : \Tms\ \Gamma\ \Delta) \to \Tm\ \Gamma\ A[\sigma] \\
    &           &&   && \to \Tms\ \Gamma\ (\Delta,A) \\
    & \pi_1     && : && \Tms\ \Gamma\ (\Delta,A) \to \Tms\ \Gamma\ \Delta \\ &
  \end{alignedat} && \ind
  \begin{alignedat}{2}
    & \id\circ && : \id \circ \sigma \equiv \sigma \\
    & \circ\id && : \sigma \circ \id \equiv \sigma \\
    & \circ\circ && : (\sigma \circ \nu) \circ \delta \equiv \sigma \circ (\nu \circ \delta) \\
    & \epsilon\eta && : \{\sigma : \Tms\ \Gamma\ \bullet\} \to \sigma \equiv \epsilon \\
    & \pi_1\beta && : \pi_1(\sigma,u) \equiv \sigma \\
    & \pi\eta  && : \pi_1\,\sigma , \pi_2\,\sigma \equiv \sigma \\
    & ,\circ  && : (\sigma,u) \circ \nu \equiv (\sigma \circ \nu),(_{[\circ]^{-1} *}u[\nu])
  \end{alignedat}
  \displaybreak[0] \\
  % Terms
  & \data\ \Tm\ \where && \data\ \Tm\ \where \\ & \ind
  \begin{alignedat}{3}
    & \pi_2     && :\ && (\sigma : \Tms\ \Gamma\ (\Delta,A)) \to \Tm\ \Gamma\ (A[\pi_1 \sigma]) \\
    & \_[\_]    && : && \Tm\ \Delta\ A \to (\sigma : \Tms\ \Gamma\ \Delta) \\
    &           &&   && \to \Tm\ \Gamma\ A[\sigma] \\
    & \lam      && : && \Tm\ (\Gamma,A)\ B \to \Tm\ \Gamma\ (\Pi\ A\ B) \\
    & \app      && : && \Tm\ \Gamma\ (\Pi\ A\ B) \to \Tm\ (\Gamma,A)\ B
  \end{alignedat} && \ind
  \begin{alignedat}{2}
    & \pi_2\beta && : \pi_2(\sigma,u) \equiv^{\pi_1\beta} u \\
    & \beta    && : \app\ (\lam u) \equiv u \\
    & \eta     && : \lam (\app\, u) \equiv u \\
    & \lam[]   && : (\lam u)[\sigma] \equiv^{\Pi[]} \lam(u[\sigma \lift A]) \\ &
  \end{alignedat}
\end{flalign*}
Equations $\Pi[]$ and $\lambda[]$ use the lifting of a substitution by a type,
defined as follows.
\begin{align*}
  & \_\lift\_      : (\sigma : \Tms\ \Gamma\ \Delta) \to (A:\Ty\ \Delta) \to
                        \Tms\ (\Gamma,A[\sigma])\ (\Delta,A) \\
  & \sigma \lift A = (\sigma \circ \pi_1\,\id) , (_{[\circ]^{-1}*}\pi_2\,\id)
\end{align*}

This syntax uses a categorical application constructor $\app$, which is
essentially the inverse of $\lam$. One may understand $\app\ f$ as the
application of $f$ to a fresh variable. In order to obtain the usual
application, denoted $\_\$\_$, this fresh variable must be substituted by the
argument. We denote this substitution of the last variable in the context by
$<\_>$.
\begin{alignat*}{2}
  & <\_> && : \Tm\ \Gamma\ A \to \Tms\ \Gamma\ (\Gamma,A) \\ & <u> && = \id\,,\,_{[\id]^{-1} *}u \\
  & \_\$\_ && : \Tm\ \Gamma\ (\Pi\ A\ B) \to (u : \Tm\ \Gamma\ A) \to \Tm\ \Gamma\ (B[<u>]) \\
  & f\ \$\ u && = (\app\, f)[<u>]
\end{alignat*}

As a simple example, let us translate the lambda term $\lambda x^A . \lambda
y^B . x$ to this syntax. We assume that $A$ is type in context $\Gamma$, and
$B$ a type in context $(\Gamma,A)$ (or in short $\Gamma:\Con$, $A:\Ty\ \Gamma$,
$B:\Ty\ (\Gamma,A)$), so that $(\Gamma,A,B)$ is a context.
We start with $\id$, intuitively the substitution containing all variables in
context.
\[ \id : \Tms\ (\Gamma,A,B)\ (\Gamma,A,B) \]
The second to last variable in the context, corresponding to $x$, is retrieved
through projections.
\[ \pi_2 (\pi_1\,\id) : \Tm\ (\Gamma,A,B)\ A[\pi_1\,\id] \]
Finally, the lambda-abstractions are added.
\[ \lam (\lam (\pi_2 (\pi_1\,\id))) : \Tm\ \Gamma\ (\Pi\ A\ (\Pi\ B\ A[\pi_1\,\id])) \]

\section{Weakenings}
\label{sec:weakening}
In this section, we introduce variables and weakenings of contexts. The
presentation is the same as in~\cite{kaposi2016normalisation}, except that the
latter uses the name `renamings' instead.

Variables, denoted by $x,y,z$, are defined as typed De Bruijn indices, with
constructors $\vz$ and $\vs$ standing for `0' and successor.
Variables can be embedded into terms by applying projections to
$\id$---intuitively, $\id$ is the substitution formed by all the variables in
context.  \begin{flalign*}
  & \data\ \Var\ : (\Gamma : \Con) \to \Ty\ \Gamma \to \Set\ \where
  && \cul\_\cur : \Var\ \Gamma\ A \to \Tm\ \Gamma\ A \\ & \ind
  \begin{alignedat}{2}
    & \vz && : \Var\ (\Gamma,A)\ (A[\pi_1\,\id]) \\
    & \vs && : \Var\ \Gamma\ A \to \Var\ (\Gamma,B)\ (A[\pi_1\,\id])
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul \vz \cur && = \pi_2\,\id \\
    & \cul \vs\,x \cur && = \cul x \cur [\pi_1\,\id]
  \end{alignedat}
\end{flalign*}
Weakening substitutions (or simply weakenings), denoted by
$\alpha,\beta,\gamma$, are substitutions composed only of variables.
This regroups the usual notions of weakening (i.e.\ forgetting a variable),
contraction, and reordering of independent variables.
Note that constructors $\epsilon$ and $\_,\_$ are overloaded due
to the similarity with substitutions.
\begin{flalign*}
  & \data\ \Vars\ : \Con \to \Con \to \Set\ \where
  && \cul\_\cur : \Vars\ \Gamma\ \Delta \to \Tms\ \Gamma\ \Delta \\ & \ind
  \begin{alignedat}{2}
    & \epsilon && : \Vars\ \Gamma\ \bullet \\
    & \_,\_ && : (\alpha : \Vars\ \Gamma\ \Delta) \to \Var\ \Gamma\ A[\cul \alpha \cur]
    \to \Vars\ \Gamma\ (\Delta,A)
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul \epsilon \cur && = \epsilon \\
    & \cul \alpha,x \cur && = \cul \alpha \cur , \cul x \cur
  \end{alignedat}
\end{flalign*}

Unlike regular substitutions, identity and composition of weakenings are not
constructors, but inductive definitions. Some auxiliary functions are required:
$\wk$ weakens the context of a weakening substitution by a type $A$, and $\_[\_]$
applies a weakening substitution to a variable. These functions all commute with
embeddings of variables and weakenings. We omit the inductive definitions and
proofs, which are simple.
\begin{flalign*} &
  \begin{alignedat}{2}
    & \wk && : (A : \Ty\ \Gamma) \to \Vars\ \Gamma\ \Delta \to \Vars\ (\Gamma,A)\ \Delta \\
    & \id && : \{\Gamma : \Con\} \to \Vars\ \Gamma\ \Gamma \\
    & \_[\_] && : \Var\ \Delta\ A \to (\alpha : \Vars\ \Gamma\ \Delta) \to \Var\ \Gamma\ (A[\cul\alpha\cur]) \\
    & \_\circ\_ && : \Vars\ \Delta\ \Theta \to \Vars\ \Gamma\ \Delta \to \Vars\ \Gamma\ \Theta
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul\wk\cur && : \cul \wk\ A\ \alpha \cur \equiv \cul \alpha \cur \circ (\pi_1\,\id) \\
    & \cul\id\cur && : \cul \,\id\, \cur \equiv \id \\
    & \cul[]\cur && : \cul x [ \alpha ] \cur \equiv \cul x \cur [ \cul \alpha \cur ] \\
    & \cul\circ\cur && : \cul \alpha \circ \beta \cur \equiv \cul \alpha \cur \circ \cul \beta \cur
  \end{alignedat}
\end{flalign*}
Contexts and weakenings form a category with these operations.
Types, terms, and substitutions can be weakened by applying a weakening
substitution, seen as a regular substitution through embedding.
These operations respects identity and composition, that is types and substitutions
are presheaves on the category of weakenings, while terms are a family of presheaves
over types. Definitions are below, with the lemmas on the right (proofs omitted).
\begin{flalign*} &
  \begin{alignedat}{2}
    & \_\ ^{+\_} && : \Ty\ \Delta \to \Vars\ \Gamma\ \Delta \to \Ty\ \Gamma \\
    & A^{+\alpha} && = A [\cul\alpha\cur] \\
    & \_\ ^{+\_} && : \Tm\ \Delta\ A \to (\alpha : \Vars\ \Gamma\ \Delta) \to \Tm\ \Gamma\ A^{+\alpha} \\
    & u^{+\alpha} && = u [\cul\alpha\cur] \\
    & \_\ ^{+\_} && : \Tms\ \Delta\ \Theta \to \Vars\ \Gamma\ \Delta \to \Tms\ \Gamma\ \Theta \\
    & \sigma^{+\alpha} && = \sigma \circ \cul\alpha\cur
  \end{alignedat} &&
  \begin{alignedat}{2}
    & +\!\id && : A^{+\id} \equiv A \\
    & +\!\circ && : A^{+ (\alpha \circ \beta)} \equiv (A^{+\alpha})^{+\beta} \\
    & +\!\id && : u^{+\id} \equiv u \\
    & +\!\circ && : u^{+ (\alpha \circ \beta)} \equiv (u^{+\alpha})^{+\beta} \\
    & +\!\id && : \sigma^{+\id} \equiv \sigma \\
    & +\!\circ && : \sigma^{+ (\alpha \circ \beta)} \equiv (\sigma^{+\alpha})^{+\beta}
  \end{alignedat}
\end{flalign*}

This will be a general pattern in later constructions and proofs: families of
sets (e.g.\ values, normal forms, \dots) have a presheaf-like structure, which
simply means that the elements can be weakened coherently.
Similarly, functions are natural transformations, i.e.\ commute with weakening,
and predicates are sub-presheaves, i.e.\ are stable under weakening.
The corresponding definitions and proofs are typically straightforward, and we
will often not mention them. We abusively denote all applications of weakenings
by $\_\ ^{+\_}$.

Finally, given a type $A$, one may consider $\wk\ A\ \id : \Vars\ (\Gamma,A)\ \Gamma$,
the weakening of the context $\Gamma$ by $A$. We abuse notations and write
$u^{+A}$ for $u^{+ (\wk\ A\ \id)}$.

\section{Normalisation Relation}
\label{sec:normalisation}
This section defines the big step normalisation algorithm using the previous
syntax of type theory. As further explained in \cref{sec:evaluation}, this
algorithm can not yet be formally defined as a function. Thus, it is defined
as a relation in order to carry out the correctness proof.

We first define values and the evaluation from terms to values, then normal
forms and the function $\q$ mapping values to normal forms. Normalisation is
done by applying evaluation followed by $\q$.

\subsection{Values}
A value is either a closure, corresponding to the delayed evaluation of a
lambda-abstraction, or a neutral value, that is the stuck application of a
variable to values. We define mutually values (denoted by $v,w$), neutral
values (denoted by $n$), and environments (substitutions composed of values,
denoted by $\rho,\omega$), together with the associated embeddings.
\begin{flalign*}
  & \data\ \Val : (\Gamma : \Con) \to \Ty\ \Gamma \to \Set\ \where
  && \cul\_\cur : \Val\ \Gamma\ A \to \Tm\ \Gamma\ A \\ & \ind
  \begin{alignedat}{3}
    & \neu   && :\ && \NV\ \Gamma\ A \to \Val\ \Gamma\ A \\
    & \clos  && : && \Tm\ (\Delta,A)\ B \to (\rho : \Env\ \Gamma\ \Delta) \\
    &        &&   && \to \Val\ \Gamma\ ((\Pi\ A\ B)[\cul \rho \cur])
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul \neu\ n \cur && = \cul n \cur \\
    & \cul \clos\ u\ \rho \cur && = (\lambda u)[\cul \rho \cur] \\ &
  \end{alignedat}
  \displaybreak[0] \\
  & \data\ \NV : (\Gamma : \Con) \to \Ty\ \Gamma \to \Set\ \where
  && \cul\_\cur : \NV\ \Gamma\ A \to \Tm\ \Gamma\ A \\ & \ind
  \begin{alignedat}{3}
    & \var && :\ && \Var\ \Gamma\ A \to \NV\ \Gamma\ A \\
    & \app && : && \NV\ \Gamma\ (\Pi\ A\ B) \to (v : \Val\ \Gamma\ A) \\
    &      &&   && \to \NV\ \Gamma\ (B[<\cul v \cur>])
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul \var\ x \cur && = \cul x \cur \\
    & \cul \app\ n\ v\cur && = \cul n \cur\,\$\,\cul v \cur \\ &
  \end{alignedat}
  \displaybreak[0] \\
  & \data\ \Env : \Con \to \Con \to \Set\ \where
  && \cul\_\cur : \Env\ \Gamma\ \Delta \to \Tms\ \Gamma\ \Delta \\ & \ind
  \begin{alignedat}{3}
    & \epsilon && :\ && \Env\ \Gamma\ \bullet \\
    & \_,\_ && : && (\rho : \Env\ \Gamma\ \Delta) \to \Val\ \Gamma\
    (A[\cul\rho\cur]) \to \Env\ \Gamma\ (\Delta,A)
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul \epsilon \cur && = \epsilon \\
    & \cul \rho,v \cur && = \cul \rho \cur , \cul v \cur
  \end{alignedat}
\end{flalign*}

This definition would be used with an unquotiented syntax such as in~\cite{chapman2009bsn},
but does not work with the quotiented syntax because values can be equivalent
as terms (formally, have equal embeddings), but not equal. For instance, in a
closure $\clos\ u\ \rho$, if the body $u$ never refers to the environment $\rho$,
then modifying $\rho$ yields a distinct but equivalent value. Then, evaluation
would map equivalent terms to distinct values, hence could not be defined on the
quotiented syntax. This is fixed by the following quotient constructor,
which forces equivalent values to be equal.
\begin{flalign*}
  & \data\ \Val\ \where \\
  & \ind \qVal : (v\ w : \Val\ \Gamma\ A) \to \cul v \cur \equiv \cul w \cur \to v \equiv w
\end{flalign*}
The corresponding result for environments can be proved by induction on contexts.
\[ \qEnv : (\rho\ \omega : \Env\ \Gamma\ \Delta) \to
  \cul \rho \cur \equiv \cul \omega \cur \to \rho \equiv \omega \]
Weakening is defined by induction on values, neutral values, and environments,
we omit the definitions and the associated lemmas. Finally, the identity
environment is defined by induction on the context, and uses weakening of
environments.
\begin{flalign*}
  & \idenv : \{\Gamma : \Con\} \to \Env\ \Gamma\ \Gamma \\ &
  \begin{alignedat}{2}
    & \idenv_{\bullet} && = \epsilon \\
    & \idenv_{\Gamma,A} && = {\idenv_{\Gamma}}^{+A} \,,\, \neu\,(\var\ \vz)
  \end{alignedat}
\end{flalign*}

\subsection{Evaluation}
\label{sec:evaluation}
The first stage of normalisation is an environment machine, which evaluate
terms in an environment, and returns values. It consists of three mutually
defined functions: $\eval$ and $\evals$ evaluate terms and substitutions
respectively in an environment, while $\_@\_$ computes the application of a
value to another.

\begin{flalign*}
  & \eval : \Tm\ \Delta\ A \to (\rho : \Env\ \Gamma\ \Delta) \to \Val\ \Gamma\ A[\cul \rho \cur] \\ &
  \begin{alignedat}{2}
    & \eval\ (\pi_2\, \sigma)\ \rho && = \Alet\ (\omega,v) = (\evals\ \sigma\ \rho)\ \Ain\ v\ \\
    & \eval\ (u[\sigma])\ \rho && = \eval\ u\ (\evals\ \sigma\ \rho) \\
    & \eval\ (\lam u)\ \rho && = \clos\ u\ \rho \\
    & \eval\ (\app\ u)\ (\rho,v) && = (\eval\ u\ \rho)\ @\ v
  \end{alignedat}
  \displaybreak[0] \\
  & \evals : \Tms\ \Delta\ \Theta \to \Env\ \Gamma\ \Delta \to \Env\ \Gamma\ \Theta \\ &
  \begin{alignedat}{2}
    & \evals\ \id\ \rho && = \rho \\
    & \evals\ (\sigma \circ \nu)\ \rho && = \evals\ \sigma\ (\evals\ \nu\ \rho) \\
    & \evals\ \epsilon\ \rho && = \epsilon \\
    & \evals\ (\sigma,u)\ \rho && = (\evals\ \sigma\ \rho) , (\eval\ u\ \rho) \\
    & \evals\ (\pi_1\, \sigma)\ \rho && = \Alet\ (\omega,v) = (\evals\ \sigma\ \rho)\ \Ain\ \omega\ \\
  \end{alignedat}
  \displaybreak[0] \\
  & \_@\_ : \Val\ \Gamma\ (\Pi\ A\ B) \to (v : \Val\ \Gamma\ A) \to \Val\ \Gamma\ B[<\cul v \cur>] \\ &
  \begin{alignedat}{2}
    & (\clos\ u\ \rho)\ @\ v && = \eval\ u\ (\rho,v) \\
    & (\neu\ n)\ @\ v && = \neu\ (\app\ n\ v)
  \end{alignedat}
\end{flalign*}
Most cases are straightforward. Note how evaluation of a lambda simply returns
a closure, delaying the evaluation of the body. The latter occurs in the first
case of $\_@\_$, as the application of a closure to a value is computed by
evaluating the body of the closure in the extended environment.
Evaluation of the projections $\pi_1$, $\pi_2$ performs a projection on an
environment, expressed through the $\Alet \dots \Ain$ construct with an
obvious meaning.

However, there are several problems with this presentation of the evaluator.
Firstly, the functions are defined by recursion on terms and substitutions,
which are QIIT, but we did not bother to verify that equality constructors
are respected. Perhaps more worryingly, the function is not structurally
recursive: the last case of $\eval$ applies $\_@\_$ to $\eval\ u\ p$, which
a priori is an arbitrary value. Thus it is not clear that the evaluator
terminates.

The proof of correctness of this algorithm is not trivial, and is the subject
of \cref{sec:correctness}. For now, we will only define the algorithm, i.e.\
we consider the previous definition as a \emph{programming} function, rather
than an (incorrect) mathematical function. In order to formally define this
algorithm, we represent it by its big step semantics, that is the relation
between inputs and outputs of the evaluator. For instance, we denote by
$\eval\ t\ \rho \Da v$ the proposition `$t$ evaluates to $v$ in environment
$\rho$'.
\begin{flalign*}
  & \data\ \eval\_\,\_\Da\_ : \Tm\ \Delta\ A \to \Env\ \Gamma\ \Delta \to
                              \Val\ \Gamma\ B \to \Prop\ \where \\ & \ind
  \begin{alignedat}{2}
    & \eval\pi_2 && : \evals\ \sigma\ \rho \Da (\omega,v) \to \eval\ (\pi_2\ \sigma)\ \rho \Da v \\
    & \eval[]    && : \evals\ \sigma\ \rho \Da \omega \to \eval\ u\ \omega \Da v \to
                      \eval\ (u[\sigma])\ \rho \Da v \\
    & \eval\lam  && : \eval\ (\lam u)\ \rho \Da (\clos\ u\ \rho) \\
    & \eval\app  && : \eval\ f\ \rho \Da g \to g\ @\ v \Da w \to \eval\ (\app\ f)\ (\rho,v) \Da w
  \end{alignedat}
  \displaybreak[0] \\
  & \data\ \evals\_\,\_\Da\_ : \Tms\ \Delta\ \Theta \to \Env\ \Gamma\ \Delta \to
                               \Env\ \Gamma\ \Theta \to \Prop \\ & \ind
  \begin{alignedat}{2}
    & \evals\id      && : \evals\ \id\ \rho \Da \rho \\
    & \evals\circ    && : \evals\ \nu\ \rho \Da \omega \to \evals\ \sigma\ \omega \Da \xi \to
                          \evals\ (\sigma \circ \nu)\ \rho \Da \xi \\
    & \evals\epsilon && : \evals\ \epsilon\ \rho \Da \epsilon \\
    & \evals,        && : \evals\ \sigma\ \rho \Da \omega \to \eval\ u\ \rho \Da v \to
                          \evals\ (\sigma, u)\ \rho \Da (\omega, v) \\
    & \evals\pi_1    && : \evals\ \sigma\ \rho \Da (\omega,v) \to \eval\ (\pi_1\ \sigma)\ \rho \Da \omega
  \end{alignedat}
  \displaybreak[0] \\
  & \data\ \_@\_\Da\_ : \Val\ \Gamma\ A \to \Val\ \Gamma\ B \to \Val\ \Gamma\ C \to \Prop \\ & \ind
  \begin{alignedat}{2}
    & @\clos && : \eval\ u\ (\rho,v) \Da w \to (\clos\ u\ \rho)\ @\ v \Da w \\
    & @\neu  && : (\neu\ n)\ @\ v \Da (\neu\ (\app\ n\ v))
  \end{alignedat}
\end{flalign*}
The types of the above relations may seem surprisingly imprecise. For instance,
the type of $\eval$ does not give any information on the type of the return
value---it is a value of some unknown type $B$---whereas we know that
it should have type $A[<\cul \rho \cur>]$ when evaluating in environment $\rho$.
Similarly, we do not even require the first argument of $@$ to be a function.
It would be possible to define the evaluation relation with more restrictive
types, but this would only complicate later proofs by requiring many additional
transports. This choice may be compared to heterogeneous equality, which can
similarly simplify proofs merely by being less restrictive than dependent
equality types.

Of course, the expected type restrictions on evaluation can still be proved as
lemmas.
\begin{lemma}
  \label{lem:evalCompl}
  \[
    \AXC{$\eval\ u\ \rho \Da v$}
    \UIC{$\cul v \cur \equiv u[ \cul\rho\cur ]$}
    \DP \quad
    \AXC{$\evals\ \sigma\ \rho \Da \omega$}
    \UIC{$\cul\omega\cur \equiv \sigma \circ \cul\rho\cur$}
    \DP \quad
    \AXC{$f\ @\ v \Da w$}
    \UIC{$\cul f \cur\ \$\ \cul v \cur \equiv \cul w \cur$}
    \DP
  \]
\end{lemma}
\begin{proof}
  By simultaneous induction on the definitions of the relations $\eval$, $\evals$, and $@$.
\end{proof}
A soundness property follows.
\begin{lemma}
  \label{lem:evalSound}
  \[
    \AXC{$\eval\ u\ \rho \Da v$}
    \AXC{$\eval\ u\ \rho \Da w$}
    \BIC{$v \equiv w$}
    \DP \quad
    \AXC{$\evals\ \sigma\ \rho \Da \omega$}
    \AXC{$\evals\ \sigma\ \rho \Da \delta$}
    \BIC{$\omega \equiv \delta$}
    \DP
  \]
  \[
    \AXC{$f\ @\ u \Da v$}
    \AXC{$f\ @\ u \Da w$}
    \BIC{$v \equiv w$}
    \DP
  \]
\end{lemma}
\begin{proof}
  Using \cref{lem:evalCompl}, and that embeddings of values and
  environments are injective by $\qVal$ and $\qEnv$.
\end{proof}

\subsection{Normal Forms}
Having defined the evaluator, we continue with the function $\q$ which maps
values to normal forms. The classic notion of \emph{$\eta$-long $\beta$-normal forms}
(see for instance~\cite{jouannaud1998rewrite}) is used, which interestingly is
shared with normalisation by evaluation (cf.~\cite{kaposi2016normalisation}).

Like values, normal forms are defined mutually with neutral normal forms,
i.e.\ the application of a variable to normal forms. An important difference
is that not all neutral normal forms are normal forms: it is only true for
neutral normal forms of the base types (i.e.\ $\U$ and $\El$). This restriction
ensures that normal forms are sufficiently $\eta$-expanded.
\begin{flalign*}
  & \data\ \Nf : (\Gamma : \Con) \to \Ty\ \Gamma \to \Set\ \where
  && \cul\_\cur : \Nf\ \Gamma\ A \to \Tm\ \Gamma\ A \\ & \ind
  \begin{alignedat}{2}
    & \lam && : \Nf\ (\Gamma,A)\ B \to \Nf\ \Gamma (\Pi\ A\ B) \\
    & \neu\U && : \NN\ \Gamma\ \U \to \Nf\ \Gamma\ \U \\
    & \neu\El && : \NN\ \Gamma\ (\El\ u) \to \Nf\ \Gamma\ (\El\ u)
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul \lam n \cur && = \lam\, \cul n \cur \\
    & \cul \neu\U\ n \cur && = \cul n \cur \\
    & \cul \neu\El\ n \cur && = \cul n \cur
  \end{alignedat} \\
  & \data\ \NN : (\Gamma : \Con) \to \Ty\ \Gamma \to \Set\ \where
  && \cul\_\cur : \NN\ \Gamma\ A \to \Tm\ \Gamma\ A \\ & \ind
  \begin{alignedat}{3}
    & \var && :\ && \Var\ \Gamma\ A \to \NN\ \Gamma\ A \\
    & \app && : && \NN\ \Gamma\ (\Pi\ A\ B) \to (n : \NN\ \Gamma\ A) \\
    &      &&   && \to \NN\ \Gamma\ (B[<\cul n \cur>])
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul \var\ x \cur && = \cul x \cur \\
    & \cul \app\ m\ n \cur && = \cul m \cur\,\$\,\cul n \cur \\ &
  \end{alignedat}
\end{flalign*}
Note that normal forms are indexed by regular types, we do not use a notion of
normal types. Indeed, normalising types and terms simultaneously only seems to
complicate matters, and it is easier to first normalise a term without worrying
about its type, then recursively normalise the type. A disadvantage of this
choice is that equality of normal forms is not a priori decidable, because it
would require to test equality of types, and in turn equality of terms.
This issue can be solved once the normalisation function is defined
by proving decidability of equality for terms, normal forms, and types
simultaneously, as shown in~\cite{kaposi2016normalisation}.

\subsection{Quote}
The function $\q$ is defined by induction on the type of the value, together
with $\qn$ which maps neutral values to neutral normal forms by recursively
applying $\q$. Like the evaluator, we begin with an informal definition as
a function, which is then translated to a relation.
\begin{flalign*}
  & \q : \{A : \Ty\} \to \Val\ \Gamma\ A \to \Nf\ \Gamma\ A \\ &
  \begin{alignedat}{2}
    & \q_{\U}\ (\neu\ v) && = \neu\U\ (\qn\ v) \\
    & \q_{(\El\ u)}\ (\neu\ v) && = \neu\El\ (\qn\ v) \\
    & \q_{(\Pi\ A\ B)}\ f       && = \lam (\q\ (f^{+A}\ @\ \neu\ (\var\ \vz)))
  \end{alignedat} \\
  & \qn : \NV\ \Gamma\ A \to \NN\ \Gamma\ A \\ &
  \begin{alignedat}{2}
    & \qn\ (\var\ x) && = \var\ x \\
    & \qn\ (\app\ f\ v) && = \app\ (\qn\ f)\ (\q\ v)
  \end{alignedat}
\end{flalign*}
A value of a base type is necessarily neutral, hence it suffice to use
$\qn$ in that case. For function types, the definition of normal forms
requires the result to be an abstraction. This is done by $\eta$-expending the
value, and applying $\q$ to the body of the resulting abstraction.
The $\eta$-expansion is somewhat technical to define. First, the function is
weakened as $f^{+A}$ to allow the introduction of a new variable of type $A$
represented by the De Bruijn index $\vz$. This variable is turned into a value
by the $\var$ and $\neu$ constructors, and the weakened function is applied
using $@$, giving the body of the $\eta$-expansion.

Beside the problems of termination and correctness with regards to quotient
constructors which already appeared in the evaluator, one may note that $\q$ is
not defined on the $\_[\_]$ type constructor. We will later show that the
definition for $\_[\_]$ can in fact be inferred from the other cases and the
equality constraints. For now we again ignore all issues by considering the big
step semantics of $\q$, with the following signature, and the expected
definition.
\begin{align*}
  & \q : \Val\ \Gamma\ A \to \Nf\ \Gamma\ A \to \Prop \\
  & \qn : \NV\ \Gamma\ A \to \NN\ \Gamma\ A \to \Prop
\end{align*}

A coherence result in the style of \cref{lem:evalCompl} is proved by
induction on the relation.
\begin{lemma}
  \label{lem:quoteCompl}
  \[
    \AXC{$\q\ v \Da n$}
    \UIC{$\cul n \cur \equiv \cul v \cur$}
    \DP \quad
    \AXC{$\qn\ m \Da n$}
    \UIC{$\cul n \cur \equiv \cul m \cur$}
    \DP
  \]
\end{lemma}

\subsection{Normalisation}
Finally, terms are normalised by evaluating in the identity environment and
applying $\q$.
\[ \norm\ u \Da n = \Sigma(v : \Val\ \Gamma\ A)\ \eval\ u\ \idenv \Da v \ \land \ \q\ v \Da n \]

With this definition, stability and completeness of BSN can already be proved.
\begin{theorem}[Completeness]
  \label{thm:completeness}
  \[
    \AXC{$\norm\ u \Da n$}
    \UIC{$\cul n \cur \equiv u$}
    \DP
  \]
\end{theorem}
\begin{proof}
  Immediate by \cref{lem:evalCompl,lem:quoteCompl}.
\end{proof}
\begin{theorem}[Stability]
  \label{thm:stability}
  \[
    \AXC{$n : \Nf\ \Gamma\ A$}
    \UIC{$\norm\ \cul n \cur \Da n$}
    \DP\quad
    \AXC{$n : \NN\ \Gamma\ A$}
    \UIC{$\Sigma(v : \NV\ \Gamma\ A)\ \eval\ \cul n \cur \Da (\neu\ v) \ \land \ \qn\ v \Da n$}
    \DP
  \]
\end{theorem}
\begin{proof}
  By simultaneous induction on normal forms and neutral normal forms.
\end{proof}


\section{Correctness of BSN}
\label{sec:correctness}
Two main results must be proved in order to establish the correctness of BSN.
Termination states that the normalisation relation is defined on every term.
\[ \forall (u : \Tm\ \Gamma\ A),\ \exists (n : \Nf\ \Gamma\ A),\ \norm\ u \Da n \]
Soundness states that normalisation can only give one result for each term.
\[
  \AXC{$\norm\ u \Da n$}
  \AXC{$\norm\ u \Da m$}
  \BIC{$n \equiv m$}
  \DP
\]
Termination and soundness together imply that the normalisation relation defines
a function from terms to normal forms, and the remaining coherence properties
(completeness and stability) have already been proved in the previous section.

In this section, we first provide a short proof of soundness using known results
on NBE.

Next, we define a partial normalisation of types, and the notion of skeleton of
a type. Together, they give a very simple induction principle for the syntax of
dependent types. Using this simplified induction principle, it is fairly
straightforward to adapt the proof of termination for simple
types~\cite{chapman2009bsn}, based on the strong computability predicate.

\subsection{Soundness, by NBE}
The original presentation of BSN for the simply-typed lambda-calculus proves
soundness using a logical binary relation, similar to the use of strong
computability for termination presented later in this section. Unfortunately,
this proof seems hard to adapt to the quotiented syntax.

However there is an alternative proof, much shorter if not as interesting.
The key observation is that BSN uses the same notion of normal forms as
normalisation by evaluation (cf.~\cite{kaposi2016normalisation} for a formal
proof of NBE for type theory---we use the very same syntax and definition of
normal forms). A direct consequence of the existence of a normalisation function
such as NBE is that there is exactly one normal form in each equivalence class
of terms, which in the quotiented syntax means that the embedding of normal
forms is injective.
\begin{theorem}
  \label{thm:nbe}
  \[ \AXC{$n,m : \Nf\ \Gamma\ A$}\AXC{$\cul n \cur \equiv \cul m \cur$}\BIC{$n \equiv m$}\DP \]
\end{theorem}
\begin{proof}
  By soundness and stability of normalisation by evaluation.
\end{proof}

\begin{theorem}[Soundness]
  \label{thm:soundness}
  \[ \AXC{$\norm\ u \Da n$}\AXC{$\norm\ u \Da m$}\BIC{$n \equiv m$}\DP \]
\end{theorem}
\begin{proof}
  Immediate by \cref{thm:completeness,thm:nbe}.
\end{proof}

It can of course be argued that defining a normalisation function using another
normalisation function defeats the object. However we think that it is interesting
to consider BSN not so much as alternative normalisation function than as an
alternative definition for the function which can also be obtained through NBE.
This proof of soundness becomes more sensible from this point of view: as soon
as we prove that the functions defined by NBE and BSN coincide (for which
completeness of BSN is a key result), all correctness properties which are known
to hold for NBE---in particular soundness---transfer to BSN.

\subsection{Substitution-Free Types}
An interesting issue was mentioned while defining $\q$: the natural definition
is by induction on types, but only considers the constructors $\U$, $\El$, and
$\Pi$, forgetting both $\_[\_]$ and the quotient constructors. In this
subsection, we show that this type of definition is in fact always correct, by
defining substitution-free types, and proving that they are isomorphic to
regular types.

Substitution free types are defined together with their embedding into regular
types.
\begin{flalign*}
  & \data\ \TV : \Con \to \Set\ \where && \cul\_\cur : \TV\ \Gamma \to \Ty\ \Gamma && \\ & \ind
  \begin{alignedat}{2}
    & \U && : \TV\ \Gamma \\
    & \El && : \Tm\ \Gamma\ \U \to \TV\ \Gamma \\
    & \Pi && : (A : \TV\ \Gamma) \to \TV\ (\Gamma,\cul A \cur) \to \TV\ \Gamma
  \end{alignedat} &&
  \begin{alignedat}{2}
    & \cul \U \cur && = \U \\
    & \cul \El\ u \cur && = \El\ u \\
    & \cul \Pi\ A\ B \cur && = \Pi\ \cul A \cur\ \cul B \cur
  \end{alignedat}
\end{flalign*}

We will now define an evaluation function from types to substitution-free types,
which will be the inverse of the embedding $\cul\_\cur$. This requires to
interpret every remaining type constructors in substitution-free types.

First, the application of a substitution to a substitution-free type is defined
inductively.
\begin{flalign*}
  & \_[\_] : \TV\ \Delta \to \Tms\ \Gamma\ \Delta \to \TV\ \Gamma && \\ &
  \begin{alignedat}{2}
    & \U [\sigma] && = \U \\
    & (\El\ u) [\sigma] && = \El (u[\sigma]) \\
    & (\Pi\ A\ B)[\sigma] && = \Pi\ (A[\sigma])\ (B[\sigma \lift \cul A \cur])
  \end{alignedat}
\end{flalign*}
The definition directly follows the equations $\U[]$, $\El[]$, and $\Pi[]$ from
the syntax of regular types. The remaining equations can be proved by induction.
\begin{align*}
  \AXC{$A : \TV\ \Gamma$}\UIC{$A[\id] \equiv A$}\DP
  && \AXC{$A : \TV\ \Theta$}
  \AXC{$\sigma : \Tms\ \Delta\ \Theta$}
  \AXC{$\nu : \Tms\ \Gamma\ \Delta$}
  \TIC{$A[\sigma \circ \nu] \equiv A[\sigma][\nu]$}\DP
\end{align*}

Put together, this defines the evaluation function: $\U$, $\El$, and $\Pi$ are
interpreted by the respective constructors, substitutions are applied using the
previous recursive definition, the equations $\U[]$, $\El[]$, and $\Pi[]$ hold
trivially, and we just verified that $[\id]$ and $[][]$ are respected.
It is easy to verify that this evaluation function is indeed the inverse of
the embedding, therefore regular and substitution-free types are isomorphic.

This gives an alternative, much simpler induction principle for types.
\begin{lemma}
  \label{lem:typeInduction}
  To define a function on types, it suffice to define it inductively for the
  constructors $\U$, $\El$, and $\Pi$.
\end{lemma}
\begin{proof}
  The hypothesis of the lemma corresponds exactly to a definition of the
  function on substitution-free types. This function is then extended to regular
  types through the isomorphism previously defined.
\end{proof}

\subsection{Type Skeletons}
If we were to immediately define strong computability, we would face a second
issue regarding the induction principle for types: it will often be the case
that when proving a result by induction on types and considering a type
$\Pi\ A\ B$, we need to apply the induction hypothesis not on $B$, but instead
on $B[\sigma]$ for some substitution $\sigma$, which is not allowed by the
induction principle of types. However, if we were to forget substitutions
altogether, then $B$ or $B[\sigma]$ would be the same. This is exactly the idea
behind the skeleton of a type: by deleting all substitutions, we obtain a
well-founded notion of size of types, for which $B$ and $B[\sigma]$ are equivalent.

Formally, a type skeleton correspond to the non-dependent structure of types:
either a base type or a function type.
\begin{align*}
  & \data\ \Sk : \Set\ \where \\ & \ind
  \begin{alignedat}{2}
    & \base && : \Sk \\
    & \Pi && : \Sk \to \Sk \to \Sk
  \end{alignedat}
\end{align*}
Defining the skeleton of a type is straightforward, and all quotient
constructors are clearly respected.
\begin{align*}
  & \skel : \Ty\ \Gamma \to \Sk \\ &
  \begin{alignedat}{2}
    & \skel\ \U && = \base \\
    & \skel\ (\El\ u) && = \base \\
    & \skel\ (\Pi\ A\ B) && = \Pi\ (\skel\ A)\ (\skel\ B) \\
    & \skel\ (A[\sigma]) && = \skel\ A
  \end{alignedat}
\end{align*}

Using the skeleton of types as size indicators for induction, the example of
problematic induction given at the beginning of this subsection becomes valid.
\begin{lemma}
  \label{lem:typeInduction2}
  To define a function $f$ on types, it suffice to
  \begin{itemize}
    \item Define $f$ on the base types $\U$ and $\El$.
    \item Define $f$ on any type $\Pi\ A\ B$, while assuming that $f$ is
      defined on $C$ for any type $C$ with the same skeleton as either $A$ or $B$.
  \end{itemize}
\end{lemma}
\begin{proof}
  The proof is the same as for \cref{lem:typeInduction}, but additionally
  uses the skeletons as size indicators to ensure that the inductive definition
  is well-founded. Formally, this means that the function is defined by
  induction on type skeletons, then by pattern matching on the types of a given
  skeleton.
\end{proof}

\subsection{Strong Computability}
The proof of termination is based on a Tait-style~\cite{tait1967} predicate
on values, called strong computability. This subsection introduces strong
computability, together with some important lemmas.

Strong computability is defined by induction on types, using \cref{lem:typeInduction2}
\begin{itemize}
  \item A value $v$ of a base type is SC if $\q$ terminates on $v$.
  \item A value $f$ of type $\Pi\ A\ B$ is SC if the application of $f$ to a
    SC value $v$ of type $A$ gives a SC result of type $B$.
\end{itemize}
\begin{flalign*}
  & \scv : \{A : \Ty\} \to \Val\ \Gamma\ A \to \Set \\ &
  \begin{alignedat}{3}
    & \scv_{\U}\ v && =\ && \Sigma(n : \Nf\ \Gamma\ \U)\ \q\ v \Da n \\
    & \scv_{(\El\ u)}\ v && =\ && \Sigma(n : \Nf\ \Gamma\ (\El\ u))\ \q\ v \Da n \\
    & \scv_{(\Pi\ A\ B)}\ f && =\ &&
    \forall(\alpha : \Vars\ \Delta\ \Gamma) (v : \Val\ \Delta\ A^{+\alpha}) \to \scv\ v \to \\
    & && && \Sigma(C : \Ty\ \Delta)\ \Sigma(w : \Val\ \Delta\ C) \\
    & && && (f^{+\alpha}\ @\ v \Da w) \ \land\ (\scv\ w) \ \land\ (\skel\ C \equiv \skel\ B)
  \end{alignedat}
\end{flalign*}

Some remarks can be made regarding the case of function types.
Firstly, stability under application is understood up to weakening, i.e.\
the argument $v$ need not be in the same context $\Gamma$ as the function $f$,
but may instead come from a weaker context $\Delta$, where the weakening
$\alpha : \Vars\ \Delta\ \Gamma$ expresses that $\Delta$ is weaker than $\Gamma$.

Secondly, as in the definition of the evaluation relation, we prefer not to
restrict the result type to simplify the upcoming proofs, hence we merely
require that there exist a value $w$ of some type $C$. However, the definition
would not be well-founded without any restriction on $C$, since we inductively
refer to strong computability at type $C$. Thus, we ask for $C$ to have the
same skeleton as $B$. In this way, strong computability for $\Pi\ A\ B$ is
defined based on strong computability for types with the same
skeleton as either $A$ or $B$.

Strong computability is extended to environments pointwise.
\begin{flalign*}
  & \sce : \Env\ \Gamma\ \Delta \to \Set \\ &
  \begin{alignedat}{2}
    & \sce\ \epsilon && = \top \\
    & \sce\ (\rho,v) && = \sce\ \rho\ \land\ \scv\ v
  \end{alignedat}
\end{flalign*}

Let us now prove some lemma on strong computability. Throughout this subsection,
we implicitly use \cref{lem:typeInduction2} when proceeding by induction on
types.
\begin{lemma}
  \label{lem:scvWk}
  Strong computability is stable under weakening:
  \[
    \AXC{$v : \Val\ \Gamma\ A$}
    \AXC{$\scv\ v$}
    \AXC{$\alpha : \Vars\ \Delta\ \Gamma$}
    \TIC{$\scv\ v^{+\alpha}$}
    \DP \qquad
    \AXC{$\rho : \Env\ \Gamma\ \Theta$}
    \AXC{$\sce\ \rho$}
    \AXC{$\alpha : \Vars\ \Delta\ \Gamma$}
    \TIC{$\sce\ \rho^{+\alpha}$}
    \DP
  \]
\end{lemma}
\begin{proof}
  For values, the proof is by induction on the type. For base types, stability
  of $\q$ under weakening is used. For function types, the proof is immediate,
  since the definition of strong computability already accounts for weakening.

  For environments, the proof is trivial by induction.
\end{proof}

\begin{lemma}
  Strong computability is a mere proposition, i.e.\ any two proofs of strong
  computability are equal.
  \label{lem:scvProp}
  \[
    \AXC{$p,q : \scv\ v$}\UIC{$p \equiv q$}\DP \qquad
    \AXC{$p,q : \sce\ \rho$}\UIC{$p \equiv q$}\DP
  \]
\end{lemma}
\begin{proof}
  For values, the proof is by induction on the type.
  For base types, we use soundness of $\q$, that is
  \[
    \AXC{$\q\ v \Da n$}
    \AXC{$\q\ v \Da m$}
    \BIC{$n \equiv m$}
    \DP
  \]
  which follows easily from \cref{lem:quoteCompl,thm:nbe}.
  For function types, \cref{lem:evalSound} is used.

  For environments, the proof is trivial by induction.
\end{proof}

The most important lemma regarding strong computability is that it implies
termination of $\q$. A form of the converse for neutral values is proved
simultaneously.
\begin{lemma}
  \label{lem:quote}
  \[
    \AXC{$v : \Val\ \Gamma\ A$}
    \AXC{$\scv\ v$}
    \RightLabel{(quote)}
    \BIC{$\Sigma(n : \Nf\ \Gamma\ A),\ \q\ v \Da n$}
    \DP
  \]
  \[
    \AXC{$v : \NV\ \Gamma\ A$}
    \AXC{$\Sigma(n : \NN\ \Gamma\ A),\ \qn\ v \Da n$}
    \RightLabel{(unquote)}
    \BIC{$\scv\ (\neu\ v)$}
    \DP
  \]
\end{lemma}
\begin{proof}
  By mutual induction on the type $A$. The base cases are trivial by
  definition of strong computability. Consider a function type $\Pi\ A\ B$.

  For the case $(quote)$, let $f$ be a strongly computable value of type $\Pi\ A\ B$.
  Following the definition of $\q$ for function types, we need to prove that
  there exist some $v : \Val\ (\Gamma,A)\ B$ and $n : \Nf\ (\Gamma,A)\ B$ such
  that
  \[ f^{+A}\ @\ \neu\ (\var\ \vz) \Da v \quad \land \quad \q\ v \Da n \]
  In this expression, the variable $\vz$ has type $A[\pi_1 \id]$. Furthermore
  $\qn$ trivially terminates on variables, hence $(unquote)$ implies that
  $\neu\ (\var\ \vz)$ is strongly computable by induction hypothesis.
  Then by definition of strong computability $f^{+A}\ @\ \neu\ (\var\ \vz) \Da v$
  holds for some strongly computable $v$, and we may verify using
  \cref{lem:evalCompl} that $v$ has type $B$. Since $v$ is strongly
  computable of type $B$, there exist by induction hypothesis
  $n : \Nf\ (\Gamma,A)\ B$ such that $\q\ v \Da n$.
  Therefore, $\q\ f \Da (\lam\ n)$.

  Inversely, for the case $(unquote)$, assume $\qn\ f \Da n$ with
  $f : \NV\ \Gamma\ (\Pi\ A\ B)$, and let us prove that $\neu\ f$ is strongly
  computable. Let $\alpha : \Vars\ \Delta\ \Gamma$ and
  $v : \Val\ \Delta\ A^{+\alpha}$ strongly computable. Let us prove that
  $\neu\ (\app\ f^{+\alpha}\ v)$ satisfies the conditions of the definition of
  strong computability for function types.
  Firstly,
  \[ (\neu\ f^{+\alpha})\ @\ v \Da (\neu\ (\app\ f^{+\alpha}\ v)) \]
  is immediate since $f$ is neutral.
  Furthermore, by induction hypothesis $(unquote)$ and definition of $\qn$,
  to prove that $\neu\ (\app\ f^{+\alpha}\ v)$ is strongly computable, it suffice
  to check that $\qn$ terminates on $f^{+\alpha}$ and $\q$ terminates on $v$.
  The former holds by hypothesis using that $\qn$ is stable by weakening,
  while the latter holds by induction hypothesis $(quote)$.
  Finally, one may verify that the type of $\neu\ (\app\ f^{+\alpha}\ v)$ can be
  expressed as $B$ with some substitutions and weakenings applied, hence its
  skeleton is the same as $B$.
  It follows that $f$ is strongly computable.
\end{proof}

\begin{lemma}
  \label{lem:idenvsc}
  The identity environment is strongly computable.
  \[ \AXC{$\Gamma : \Con$}\UIC{$\sce\ \idenv_{\Gamma}$}\DP \]
\end{lemma}
\begin{proof}
  \Cref{lem:quote} implies that all variables are strongly computable
  because they are neutral values for which $\qn$ trivially terminates. The
  result follows by induction on $\Gamma$, using \cref{lem:scvWk}.
\end{proof}

\subsection{Termination}
All the tools are now available to prove the main termination result.
\begin{theorem}
  \label{thm:eval}
  Evaluation in a strongly computable environment terminates, and yields a
  strongly computable result.
  \[
    \AXC{$u : \Tm\ \Gamma\ A$}
    \AXC{$\rho : \Env\ \Delta\ \Gamma$}
    \AXC{$\sce\ \rho$}
    \TIC{$\Sigma(B : \Ty\ \Delta)\Sigma(v : \Val\ \Delta\ B)\ \eval\ u\ \rho \Da v\ \land\ \scv\ v$}
    \DP
  \]
  \[
    \AXC{$\sigma : \Tms\ \Gamma\ \Theta$}
    \AXC{$\rho : \Env\ \Delta\ \Gamma$}
    \AXC{$\sce\ \rho$}
    \TIC{$\Sigma(\nu : \Env\ \Gamma\ \Theta)\ \evals\ \sigma\ \rho \Da \nu\ \land\ \sce\ \nu$}
    \DP
  \]
\end{theorem}
The theorem is proved by induction on terms and substitutions. Regular
constructors are unproblematic, in the sense that the proofs does not change
significantly compared to the case of an unquotiented syntax. However, we also
need to verify that quotient constructors are respected, i.e.\ that for every
equality constructor $u \equiv v$, the proof (seen as a function) of
\cref{thm:eval} gives equal results on $u$ and $v$.

A simple way to ensure this is to prove that the types corresponding to
\cref{thm:eval} are mere propositions. In that case, when considering
an equality constructor $u \equiv v$, the result of a proof of
\cref{thm:eval} on $u$ and $v$ will necessarily be equal since both are
elements of the same mere proposition.
\begin{lemma}
  \label{lem:evalProp}
  For any $u : \Tm\ \Gamma\ A$, $\sigma : \Tms\ \Gamma\ \Theta$ and
  $\rho : \Env\ \Delta\ \Gamma$, the following types are mere propositions.
  \begin{align*}
    & \Sigma(B : \Ty\ \Delta)\Sigma(v : \Val\ \Delta\ B)\ \eval\ u\ \rho \Da v\ \land\ \scv\ v \\
    & \Sigma(\nu : \Env\ \Gamma\ \Theta)\ \evals\ \sigma\ \rho \Da \nu\ \land\ \sce\ \nu
  \end{align*}
\end{lemma}
\begin{proof}
  By \cref{lem:evalSound}, a term can only evaluate to a single value $v$.
  Furthermore, the types $\eval\ u\ \rho \Da v$ and $\scv\ v$ are mere
  propositions, by definition and by \cref{lem:scvProp} respectively.
  The result follows. The proof is similar in the case of substitutions.
\end{proof}

\begin{proof}[Proof of \cref{thm:eval}]
  By induction on terms and substitutions. We split the constructors into three
  groups:
  \begin{itemize}
  \item All quotient constructors are respected by \cref{lem:evalProp}.
  \item Almost all regular constructors are very straightforward: the result of
    evaluation is obtained by following the definition of the evaluator and
    applying the induction hypotheses, and strong computability of the result
    comes directly from the hypotheses. The exceptions to this pattern are $\lam$
    and $\app$, for which we give more detailed proofs below.
  \item For an abstraction $\lam u$ of type $\Pi\ A\ B$ evaluated in a strongly
    computable environment $\rho : \Env\ \Delta\ \Gamma$, evaluation is trivial
    since it simply yields the closure $\clos\ u\ \rho$. Let us show that this
    closure is strongly computable.

    Let $\alpha : \Vars\ \Theta\ \Delta$, and $v : \Val\ \Theta\ (A[\cul \rho \cur]^{+\alpha})$
    strongly computable. Then by \cref{lem:scvWk}, $(\rho^{+\alpha},v)$ is
    a strongly computable environment, hence by induction hypothesis there exists
    $w$ strongly computable such that $\eval\ u\ (\rho^{+\alpha},v) \Da w$.
    It follows that $(\clos\ u\ \rho)^{+\alpha}\ @\ v \Da w$. Finally, we
    may verify using \cref{lem:evalCompl} that the type of $w$ must have
    the same skeleton as $B$. It follows that $\clos\ u\ \rho$ is strongly
    computable.
  \item Consider an application $\app\ u$ with $u : \Tm\ \Gamma\ (\Pi\ A\ B)$
    evaluated in a strongly computable environment $(\rho,v) : \Env\ \Delta\ (\Gamma,A)$.
    By induction hypothesis, there exists $f$ strongly computable such that
    $\eval\ u\ \rho \Da f$. It can be verified using \cref{lem:evalCompl}
    that $f$ has type $\Pi\ (A[\cul \rho \cur])\ (B[\cul \rho \cur \lift A])$.
    Hence, because $f$ and $v$ are strongly computable, there exist $w$ strongly
    computable such that $f\ @\ v \Da w$. Then we obtain by the definition of
    the evaluation relation that $\eval\ (\app\ u)\ (\rho,v) \Da w$, proving
    the result.
  \end{itemize}
\end{proof}

\begin{theorem}[Termination]
  \label{thm:termination}
  Normalisation terminates.
  \[ \AXC{$u : \Tm\ \Gamma\ A$}\UIC{$\Sigma(n : \Nf\ \Gamma\ A),\ \norm\ u \Da n$}\DP \]
\end{theorem}
\begin{proof}
  Let $u : \Tm\ \Gamma\ A$. By \cref{lem:idenvsc,thm:eval},
  there exist $v$ strongly computable such that $\eval\ u\ \idenv \Da v$.
  By \cref{lem:evalCompl}, one may verify that $v$ has type $A$.
  Finally, by \cref{lem:quote}, there exist $n : \Nf\ \Gamma\ A$ such that
  $\q\ v \Da n$. It follows that $\norm\ u \Da n$.
\end{proof}

By \cref{thm:soundness,thm:termination}, $\norm$ defines a
function from quotiented terms to normal forms, and by
\cref{thm:completeness,thm:stability}, it is the inverse of
the embedding of normal forms. Therefore, we have proved that big step
normalisation defines a normalisation function.

\section{Formalisation of BSN in a Cubical Type Theory}
\label{sec:cubical}
Most of the present work has been formalised~\cite{formalisation} using
Agda~\cite{norell2007agda}. Precisely, \cref{sec:syntax,sec:weakening,sec:normalisation}
have been fully formalised, and \cref{sec:correctness} partially so---what
remains to do in the latter is equality reasoning.
This formalisation is expressed in a cubical type theory (CTT, cf.~\cite{cchm})
using the cubical mode of Agda. This differs from the the present paper, which
uses a strict type theory for simplicity. The choice of CTT allows to easily
express QIIT as a special case of higher inductive types (HIT, cf.~\cite{hott}),
which from the technical point of view is a notable improvement over previous
implementations of QIIT in non-cubical Agda, which had to introduce all quotient
constructors as additional axioms (e.g.~\cite{kaposi2016normalisation,kaposi2016type}).

As explained in~\cite{kaposi2016type}, simply considering a QIIT as a special
case of HIT leads to unexpected results. For instance, in the case of the
quotiented syntax, $\U[]$ and $[\id]$ give two proofs of $\U[\id] \equiv \U$,
and these proofs are distinct in a non-strict type theory. Therefore, this naive
implementation of QIIT leads to a syntax which is not a set in the type theoretic
sense, i.e.\ uniqueness of identity proofs (UIP) does not holds.
It follows by Hedberg's theorem~\cite{hedberg1998coherence} that equality is
undecidable in this syntax, which is definitively not what was expected.

The solution is to truncate the syntax to a set, by the addition of the
following constructors:
\begin{alignat*}{2}
  & \isSet\Ty && : \{A\ B : \Ty\ \Gamma\}\ (p\ q : A \equiv B) \to p \equiv q \\
  & \isSet\Tms && : \{\sigma\ \nu : \Tms\ \Gamma\ \Delta\}\ (p\ q : \sigma \equiv \nu) \to p \equiv q \\
  & \isSet\Tm && : \{s\ t : \Tm\ \Gamma\ A\}\ (p\ q : s \equiv t) \to p \equiv q
\end{alignat*}
Note that the corresponding constructor for contexts is unnecessary, because
it can be proved that contexts form a set from the fact that types are a
family of sets.

In order to adapt the proof of big step normalisation to CTT with this
implementation of QIIT, there are two problems to solve:
\begin{itemize}
\item The proof of BSN uses the UIP axiom of the strict type theory.\footnote{%
    While we never explicitly refer to the UIP axiom in this presentation of the
    proof, it is used whenever we prove a lemma of the form
    $L : (x : A) \to f(x) \equiv g(x)$ by induction on a QIIT $A$.
    Indeed, for a quotient constructor of type $a \equiv b$ in $A$, we need to
    provide an equality between equalities $L(a) \equiv L(b)$. This is trivial
    with UIP---hence why such cases are neglected in the proof---but is
    in general problematic in a non-strict metatheory.
    An example is the coherence lemmas for weakening of values.
  }
  Since we lose this axiom in CTT, its uses must be replaced.
\item The additional truncation constructors of QIIT must be taken into account
  whenever we use induction on a QIIT.
\end{itemize}
Both problems can be solved together by proving that all the types considered
in the proof of BSN are in fact sets.
Indeed, any use of the UIP axiom can then be replaced by the proof of UIP for
the appropriate type, and when defining a function by induction on a QIIT, the
set-truncation constructor can be mapped to the proof that the codomain is a set.

We will not detail all the proofs of UIP because they are fairly repetitive, but
we will explain the general techniques used.
There are some trivial cases: all QIIT (terms, types, values) are explicitly truncated to sets.
Mere propositions (the big step relations, strong computability) are always sets.
What remains are regular inductive types, such as variables, normal forms, substitution-free types\dots{}
For such types, Hedberg's theorem~\cite{hedberg1998coherence} is an extremely
useful tool. For instance, it is easy to verify that equality of variables is
decidable, which implies that they are a set. Even for types which do not a
priori have decidable equality (e.g.\ normal forms), it is still possible to
adapt the techniques and lemmas used for Hedberg's theorem to prove UIP.

\section{Conclusion and Further Work}
We have formalised big step normalisation for a simple dependent type theory,
and proved its correctness. Crucially, a quotiented syntax of type theory based
on QIIT is used to reduce the complexity of this proof. While the proof of BSN
for type theory shares many similarities with the case of the simply-typed
lambda-calculus, it requires some additional steps, for instance a simplified
induction principle for the syntax of types.

This work is also an interesting application of the QIIT syntax of type theory,
since it provides an example in which using this syntax has an important impact
on the proof. The implementation of the QIIT syntax using HIT in cubical Agda,
and its use in the formalisation of BSN is also a practical validation of
ideas which were developed in~\cite{kaposi2016type}.

Since we have only considered a minimalist type theory in this work, it is
natural to try to extend it.
A first step in this direction could be the addition of some inductive types.
This was already done in the non-dependently typed case
in~\cite{chapman2009bsn}, by adding integers (System T).
In order to handle inductive types in BSN, the general idea is to add the
inductive constructors to values and normal forms, and add the elimination principles to
neutral values and neutral normal forms, adapting $\eval$ and $\q$ accordingly.
A next step could then be to add $W$-types, so as to allow the use of
arbitrary inductive types.
Another equally interesting extension would be to replace the abstract
universe $\U$---which contains no closed terms---with a more useful universe
equipped with type constructors.

\bibliography{types.bib}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
